{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import urllib\n",
    "from urllib.error import URLError, HTTPError\n",
    "import requests\n",
    "\n",
    "# Functions and classes for loading and using the Inception model.\n",
    "from inception import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Inception v3 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "inception.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception.Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Transfer Values\n",
    "Caching the transfer values of the inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception.inception import transfer_values_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv('Farfetch/newmaster.csv')\n",
    "image_links = file.iloc[:,1]\n",
    "image_links = list(image_links)\n",
    "\n",
    "#y_true = np.loadtxt('Farfetch/true.csv', delimiter=',', skiprows=0)\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "\n",
    "headers={'User-Agent':user_agent,} \n",
    "\n",
    "transfer_values_train = []\n",
    "\n",
    "bekar = []\n",
    "\n",
    "for i in range(len(image_links)):\n",
    "    #print(i)\n",
    "    pa = str(i+1) + \"_mm.jpeg\"\n",
    "    img = cv2.imread('Farfetch master images/' + pa)\n",
    "    img = np.array(img)\n",
    "    imgr = cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )\n",
    "    new_img = np.zeros((len(imgr),len(imgr[0]),3))\n",
    "    for ii in range(len(imgr)):\n",
    "        for jj in range(len(imgr[0])):\n",
    "            new_img[ii][jj][0] = imgr[ii][jj]\n",
    "            new_img[ii][jj][1] = imgr[ii][jj]\n",
    "            new_img[ii][jj][2] = imgr[ii][jj]\n",
    "    img_len = len(new_img.shape)\n",
    "    if img_len < 3:\n",
    "        bekar.append(i)\n",
    "        print(\"Bekaar\")\n",
    "        continue\n",
    "    #res = transfer_values_cache(cache_path='inception/cachedparams/inception_clothing_train.pkl',\n",
    "    #                            images=[img],\n",
    "    #                            model=model)\n",
    "    \n",
    "    res = model.transfer_values(image=new_img)\n",
    "    \n",
    "    transfer_values_train.append(res)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24548, 2048)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_values_train = np.array(transfer_values_train)\n",
    "transfer_values_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(transfer_values_train[0])\n",
    "#plt.show()\n",
    "#plt.plot(transfer_values_train[1])\n",
    "#plt.show()\n",
    "np.savetxt(\"inception/transfer_values_cache_gray.csv\", transfer_values_train, delimiter=\",\")\n",
    "#file = pd.DataFrame(transfer_values_train)\n",
    "#file.to_csv('inception/transfer_values_cache_gray_pandas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['jackets_blazers', 'underwear_brief_or_boxers', 'trousers_chinos','trousers_cropped', 'jackets_denim',\n",
    "          'jeans_denim', 'trousers_drop_crotch', 'jackets_leather', 'shorts', 'T-shirt']\n",
    "n_class = 10\n",
    "n_dim = 2048\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_dim], name='x')\n",
    "\n",
    "y_true_labels = tf.placeholder(tf.float32, shape=[None, n_class], name='y_true_labels')\n",
    "\n",
    "n_hidden_1 = 2048\n",
    "n_hidden_2 = 2048\n",
    "\n",
    "weigths = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_class])),\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class])),\n",
    "}\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(x, weigths['h1']), biases['b1'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "layer_2 = tf.add(tf.matmul(layer_1, weigths['h2']), biases['b2'])\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "y_pred_layer = tf.matmul(layer_2, weigths['out']) + biases['out']\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred_layer, axis=1, name='y_pred_cls')\n",
    "\n",
    "y_pred_prbl = tf.nn.softmax(y_pred_layer, name='y_pred_prbl')\n",
    "\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_pred_layer,labels=y_true_labels))\n",
    "\n",
    "learning_rate=1e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "global_step = tf.Variable(initial_value=0,\n",
    "                          name='global_step', trainable=False)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_chal = np.loadtxt('Farfetch/true.csv', delimiter=',', skiprows=0)\n",
    "\n",
    "train_batch_size = 64\n",
    "num_iterations = 10000\n",
    "\n",
    "def random_batch():\n",
    "    num_images = len(transfer_values_train)\n",
    "\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random x and y-values.\n",
    "    # We use the transfer-values instead of images as x-values.\n",
    "    x_batch = transfer_values_train[idx]\n",
    "    y_batch = y_true_chal[idx]\n",
    "\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def optimize():\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true_labels: y_true_batch}\n",
    "\n",
    "        i_global, _ = sess.run([global_step, optimizer],\n",
    "                                  feed_dict=feed_dict_train)\n",
    "\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            batch_acc = sess.run(accuracy,\n",
    "                                    feed_dict=feed_dict_train)\n",
    "\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ess.close()\n",
    "#optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
